I"h<h3 id="full-stack-web-application">Full-Stack Web Application</h3>

<p>A search engine for crawled tweet data. With a Lucene Index, this search engine has the ability to search millions of tweets and return the most recent and relevant results based on a user query.</p>

<h5 id="project-pipeline-back-end--spring-front-end--react-twitter-dev-api-twitter-4j">Project Pipeline: Back End – Spring, Front End – React, Twitter Dev API, Twitter 4j</h5>

<h2 id="crawl-and-indexing">Crawl and Indexing</h2>

<h3 id="crawl">Crawl</h3>

<p>To crawl twitter, a connection to the Twitter API using a Twitter 4j object and developer keys was made, opening up a stream of tweets. For the tweets, there are two explicit parameters:</p>
<ul>
  <li>Tweets tagged with “English” language</li>
  <li>GPS bounding box for the United States of America</li>
</ul>

<p>Example crawled tweets are located <a href="https://github.com/athom031/TwitterCrawlAndSearch/tree/master/crawl_index/data-sample">here</a>.</p>

<p>Initially, crawled data also included:</p>
<ul>
  <li>Datetime</li>
  <li>Geolocation (Latitude, Longitude)</li>
  <li>User</li>
</ul>

<p>But embedding tweets in front-end application only needed the unique Tweet ID.&lt;/br&gt;
Text and timestamp is kept as parameters for the actual search feature.</p>

<h3 id="indexing">Indexing</h3>

<p>The index structure generated uses the Lucene library object IndexWriter. The index is built by loading all of the .JSON objects in the .JSON line formatted files into memory which are then parsed to create documents for the lucene inde. Those .JSON objects are parsed to create the documents for the Lucene index on  disk. We used a Lucene disk directory instead of a Lucene RAM directory so the index could easily persist for searching in Part B.2.</p>

<p>When a .JSON object (a Tweet) is parsed, the text of the Tweet is stored as a TextField in the index’s document. This is the baseline used when searching the index later. The username, date, latitude, longitude, and url (if it exists) of the Tweet are stored as document values without indexing (for Part B.2). The timestamp of the Tweet is stored twice: once as a NumericDocValuesField (used for search score boosting) and once as a LongPoint (intended for drill down search functionality if implemented). The Tweet’s latitude and longitude are also stored as DoublePoints (in case the functionality of the application would grow to include searching by a user’s GPS coordinates).</p>

<p>B.2: Create a Web-based interface</p>

<p>Search Algorithm.</p>

<p>B.1: Build index using Lucene
The search algorithm for Tweets uses a combination of relevance and time. A 
QueryParser object is created with the Tweet text field set as the default field for query terms, and a standard analyzer is set when parsing queries. A search is completed in four steps:</p>

<p>A Query object is created by passing the query string into the QueryParser parse() method.
A FunctionQuery object is created using a LongFieldSource of the Lucene index’s timestamp field.
A CustomScoreQuery object is created using the Query object as the subquery and the FunctionQuery object as the scoring query.
The CustomScoreQuery is passed to the Lucene index search() method to generate the results for the front-end.</p>

<p>We used all of the default hyperparameters for the FunctionQuery object and the CustomScoreQuery object (taking the LongFieldSource timestamp and multiplying it by 0.01 for the CustomScoreQuery boost). This algorithm gives more recent Tweets higher weight when scoring as their timestamp contains a larger long value when boosting the subquery. We verified that a Tweet’s search result ranking would be boosted by comparing results from the CustomScoreQuery object and results from the unboosted Query object.</p>

<h2 id="web-application">Web Application</h2>

<p>Phase 1: Crawl</p>

<p>Phase 2: Index</p>

<p>Phase 3: BackEnd</p>

<p>Phase 4: FrontEnd</p>

<h1 id="demo-images">Demo Images</h1>
<ol>
  <li>Interface to register users and save user data to mongoDB.</li>
</ol>

<p><img src="http://localhost:4000/assets/Files/UserLocationDemo/Register.png" /></p>

<ol>
  <li>User Homepage where users can update their information.</li>
</ol>

<p><img src="http://localhost:4000/assets/Files/UserLocationDemo/Login.png" /></p>

<ol>
  <li>Client application that visualizes user location and activity.</li>
</ol>

<p><img src="http://localhost:4000/assets/Files/UserLocationDemo/Visualization.png" /></p>

<h3 id="github-repo">Github Repo</h3>

<p><a href="https://github.com/athom031/TwitterCrawlAndSearch">Check It Out!</a></p>
<h5 id="setup-instructions-included">Setup Instructions Included</h5>
:ET