I"<<p>A search engine for crawled tweet data. With a Lucene Index, this search engine has the ability to search millions of tweets and return the most recent and relevant results based on a user query.</p>

<h5 id="project-pipeline-back-end--spring-front-end--react-twitter-dev-api-twitter-4j">Project Pipeline: Back End ‚Äì Spring, Front End ‚Äì React, Twitter Dev API, Twitter 4j</h5>

<p><img src="http://localhost:4000/assets/Files/TwitterSearch/front_end_search.png" /></p>

<h2 id="crawl-and-indexing">Crawl and Indexing</h2>

<h3 id="crawl">Crawl</h3>

<p>To crawl twitter, a connection to the Twitter API using a Twitter 4j object and developer keys was made, opening up a stream of tweets. For the tweets, there are two explicit parameters:</p>
<ul>
  <li>Tweets tagged with ‚ÄúEnglish‚Äù language</li>
  <li>GPS bounding box for the United States of America</li>
</ul>

<p>Example crawled tweets are located <a href="https://github.com/athom031/TwitterCrawlAndSearch/tree/master/crawl_index/data-sample">here</a>.</p>

<p>Initially, crawled data also included:</p>
<ul>
  <li>Datetime</li>
  <li>Geolocation (Latitude, Longitude)</li>
  <li>User</li>
</ul>

<p>But embedding tweets in front-end application only needed the unique Tweet ID.&lt;/br&gt;
Text and timestamp is kept as parameters for the actual search feature.</p>

<h3 id="indexing">Indexing</h3>

<p>The index structure generated uses the Lucene library object IndexWriter. The index is built by loading all of the .JSON objects in the .JSON line formatted files into memory which are then parsed to create documents for the lucene index.</p>

<p>When a .JSON object (a Tweet) is parsed, the text of the Tweet is stored as a TextField in the index‚Äôs document. This is the baseline used when searching the index later. The ID is not used in the tweet itself but is primarily used when representing the tweet on the front end. The timestamp of the Tweet is stored twice: once as a NumericDocValuesField (used for search score boosting) and once as a LongPoint (for drill down serach functionality).</p>

<h2 id="web-application">Web Application</h2>

<h3 id="back-end">Back End</h3>

<p>The LuceneBuilder Class was manipulated to fit the contraints of the Spring framework to create a working backend for search queries. But the default Spring framework proved erraneous due to the front end and back end being on local host in development. This meant that cross origin request errors were not linking the front end and backend properly. Therefore a more specialized <a href="https://spring.io/guides/gs/rest-service-cors/">framework</a> was used.</p>

<p><img src="http://localhost:4000/assets/Files/TwitterSearch/back_end.png" /></p>

<h3 id="front-end">Front End</h3>

<p>The react twitter embed <a href="https://www.npmjs.com/package/react-twitter-embed">component</a> made displaying the relevant tweets quite easy. The only difficulty was that the entire project, initially, was collecting different tweet data. So the Twitter Crawl and Index had to be changed accordingly.</p>

<p>The website changes based on the current state of the App class (depending on whether or not a user has entered a query). Once the query is submitted, it calls the front end to get the ID‚Äôs of the 10 most relevant tweets, and uses the embed component to display the tweets in a familiar way.</p>

<p><img src="http://localhost:4000/assets/Files/TwitterSearch/front_end_result.png" /></p>

<h3 id="github-repo">Github Repo</h3>

<p><a href="https://github.com/athom031/TwitterCrawlAndSearch">Check It Out!</a></p>
<h5 id="setup-instructions-included">Setup Instructions Included</h5>
:ET